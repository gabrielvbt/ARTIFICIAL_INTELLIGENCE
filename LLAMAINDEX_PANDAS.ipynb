{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da57aa8d",
   "metadata": {},
   "source": [
    "#### bibliotecas necessárias\n",
    "- pandas==2.2.2\n",
    "- llama-index==0.11.20\n",
    "- llama-index-llms-groq==0.2.0\n",
    "- llama-index-experimental==0.4.0\n",
    "- gradio==5.4.0\n",
    "- fpdf==1.7.2\n",
    "\n",
    "pip install llama-index==0.11.20 && pip install llama-index-llms-groq==0.2.0 && pip install llama-index-experimental==0.4.0 && pip install gradio==5.4.0 && pip install fpdf==1.7.2\n",
    "\n",
    "- OBS: Também é necessário uma key atravez do https://groq.com, sinalizado na variável \"groq_key\" na celula abaixo.\n",
    "- OBS2: Bem como um arquivo para análise, no caso, para este projeto utilizamos as informações de uma tabela fictícia da Valquíria Alencar, instrutora do curso de LLM LlamaIndex na Alura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058da079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textwrap\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.experimental.query_engine import PandasQueryEngine\n",
    "groq_key = ''\n",
    "url = 'https://github.com/alura-cursos/llamaIndex_pandas_query/blob/main/Dados/vendas.csv'\n",
    "\n",
    "Settings.llm = Groq(model='llama3-70b-8192', api_key=groq_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bba848",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2944350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A FORMA MAIS DIRETA DE RESPOSTAS UTILIZANDO QUERY_ENGINE\n",
    "query_engine = PandasQueryEngine(df=DF, verbose=True)\n",
    "\n",
    "response = query_engine.query('Qual a forma de pagamento mais utilizada?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb12e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESPOSTAS MAIS COMPLETAS ALÉM DO VALOR FINAL, UMA EXPLICAÇÃO\n",
    "# TEXTWRAP É APENAS PARA FACILITAR A VISUALIZAÇÃO, NÃO É NECESSÁRIO\n",
    "query_engine = PandasQueryEngine(df=DF, verbose=True, synthesize_response=True)\n",
    "\n",
    "response = query_engine.query('Qual a média de avaliação para cada filial?')\n",
    "print(textwrap.fill(response.response, width=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c18c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# É POSSIVEL FAZER PLOTAGEM DE GRAFICOS, UMA VEZ QUE O PANDAS POSSUI O PLOT\n",
    "query_engine = PandasQueryEngine(df=DF, verbose=True, synthesize_response=True)\n",
    "\n",
    "response = query_engine.query('Você pode plotar a distribuição das avaliações?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc640f1",
   "metadata": {},
   "source": [
    "Quando pedimos uma ação do modelo que não seja uma pergunta, como se fosse uma ordem, o modelo pode responder sem a formatação de linguagem (portugues), e nos trás uma resposta em inglês. Na maioria dos cenários isto é um problema, portanto, vamos fazer os ajustes necessários no prompt\n",
    "\n",
    "query_engine = PandasQueryEngine(df=DF, verbose=True, synthesize_response=True)\n",
    "\n",
    "response = query_engine.query('Plote a distribuição das avaliações')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fba3d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.experimental.query_engine.pandas import PandasInstructionParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b6eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO PARA OBTER UMA DESCRIÇÃO DAS COLUNAS DO DATAFRAME\n",
    "def descricao_colunas(DF):\n",
    "    descricao = '\\n'.join([f\"`{col}`: {str(DF[col].dtype)}\" for col in DF.columns])\n",
    "    return 'Aqui estão os detalhes das colunas do DataFrame:\\n' + descricao\n",
    "\n",
    "# INSTRUÇÕES PARA ORIENTAR O MODELO A CONVERTER UMA CONSULTA EM LINGUAGEM NATURAL EM CÓDIGO PYTHON EXECUTÁVEL COM A BIBLIOTECA PANDAS\n",
    "instruction_str = (\"1. Converta a consulta para código Python executável usando Pandas.\\n\"\n",
    "                    \"2. A linha final do código deve ser uma expressão Python que possa ser chamada com a função `eval()`.\\n\"\n",
    "                    \"3. O código deve representar uma solução para a consulta.\\n\"\n",
    "                    \"4. IMPRIMA APENAS A EXPRESSÃO.\\n\"\n",
    "                    \"5. Não coloque a expressão entre aspas.\\n\")\n",
    "\n",
    "# PROMPT QUE INFORMA AO MODELO OS PARAMETROS MAIS BASICOS DAS PERGUNTAS INICIAIS; DATAFRAME, PYTHON, RESULTADO, ETC\n",
    "pandas_prompt_str = (\"Você está trabalhando com um dataframe do pandas em Python chamado `DF`.\\n\"\n",
    "                    \"{colunas_detalhes}\\n\\n\"\n",
    "                    \"Este é o resultado de `print(DF.head())`:\\n\"\n",
    "                    \"{df_str}\\n\\n\"\n",
    "                    \"Siga estas instruções:\\n\"\n",
    "                    \"{instruction_str}\\n\"\n",
    "                    \"Consulta: {query_str}\\n\\n\"\n",
    "                    \"Expressão:\")\n",
    "\n",
    "# GUIA PARA SINTETIZAR A RESPOSTA ATRAVÉS DA PERGUNTA FEITA\n",
    "response_synthesis_prompt_str = (\"Dada uma pergunta de entrada, atue como analista de dados e elabore uma resposta a partir dos resultados da consulta.\\n\"\n",
    "                                \"Responda de forma natural, sem introduções como 'A resposta é:' ou algo semelhante.\\n\"\n",
    "                                \"Consulta: {query_str}\\n\\n\"\n",
    "                                \"Instruções do Pandas (opcional):\\n{pandas_instructions}\\n\\n\"\n",
    "                                \"Saída do Pandas: {pandas_output}\\n\\n\"\n",
    "                                \"Resposta:\"\n",
    "                                \"Ao final, exibir o código usado para gerar a resposta, no formato: O código utilizado foi {pandas_instructions}\")\n",
    "\n",
    "# OBTEM INSTRUÇOES DO PANDAS\n",
    "pandas_prompt = PromptTemplate(pandas_prompt_str).partial_format(instruction_str=instruction_str, colunas_detalhes=descricao_colunas(DF), df_str=DF.head(5))\n",
    "# EXECUTA AS INSTRUÇÕES\n",
    "pandas_output_parser = PandasInstructionParser(DF)\n",
    "# SINTETIZA A RESPOSTA\n",
    "response_synthesis_prompt = PromptTemplate(response_synthesis_prompt_str)\n",
    "\n",
    "llm = Groq(model='llama3-70b-8192', api_key=groq_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e381513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import(QueryPipeline as QP, Link, InputComponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b6092",
   "metadata": {},
   "outputs": [],
   "source": [
    "qp = QP(modules={'input': InputComponent(),\n",
    "                 'pandas_prompt': pandas_prompt,\n",
    "                 'llm1': llm,\n",
    "                 'pandas_output_parser': pandas_output_parser,\n",
    "                 'response_synthesis_prompt': response_synthesis_prompt,\n",
    "                 'llm2': llm}, verbose=True)\n",
    "\n",
    "# DEFININDO A CADEIA DE EVENTOS DO PIPELINE\n",
    "qp.add_chain(['input', 'pandas_prompt', 'llm1', 'pandas_output_parser'])\n",
    "\n",
    "# UNINDO OS PROCESSOS (LINKS)\n",
    "qp.add_links([Link('input', 'response_synthesis_prompt', dest_key='query_str'),\n",
    "              Link('llm1', 'response_synthesis_prompt', dest_key='pandas_instructions'),\n",
    "              Link('pandas_outrput_parser', 'response_synthesis_prompt', dest_key='pandas_output')])\n",
    "\n",
    "qp.add_link('response_synthesis_prompt', 'llm2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf274ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qp.run(query_str='Qual é a média gasta por cada tipo de cliente?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c543258",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = response.message.content\n",
    "texto_format = textwrap.fill(texto, width=100)\n",
    "texto_format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233f4a45",
   "metadata": {},
   "source": [
    "### APLICAÇÃO FRONTEND PARA CHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880894fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def load_data(file_path, DF_ESTADO):\n",
    "    if (file_path is None) | (file_path == ''):\n",
    "        return 'Faça o upload do arquivo excel para que seja analisado'\n",
    "    try:\n",
    "        DF = pd.read_excel(file_path)\n",
    "        return 'Arquivo carregado com sucesso!', DF\n",
    "    except Exception as ERROR:\n",
    "        return f'Erro ao carregar arquivo: {str(ERROR)}', DF_ESTADO\n",
    "    \n",
    "# ============== SERÁ NECESSÁRIO CRIAR AS QUERYS DAS CELULAS ACIMA EM FORMATO DE FUNÇÕES: ===================\n",
    "# ABAIXO ESTA A CELULA ONDE FOI CONTRUIDA A QUERY EM FORMA DE FUNÇÕES:\n",
    "def descrição_colunas(df):\n",
    "    descrição = '\\n'.join([f\"`{col}`: {str(df[col].dtype)}\" for col in df.columns])\n",
    "    return \"Aqui estão os detalhes das colunas do dataframe:\\n\" + descrição\n",
    "\n",
    "def pipeline_consulta(df):\n",
    "    instruction_str = (\"1. Converta a consulta para código Python executável usando Pandas.\\n\"\n",
    "                        \"2. A linha final do código deve ser uma expressão Python que possa ser chamada com a função `eval()`.\\n\"\n",
    "                        \"3. O código deve representar uma solução para a consulta.\\n\"\n",
    "                        \"4. IMPRIMA APENAS A EXPRESSÃO.\\n\"\n",
    "                        \"5. Não coloque a expressão entre aspas.\\n\")\n",
    "\n",
    "    # PROMPT QUE INFORMA AO MODELO OS PARAMETROS MAIS BASICOS DAS PERGUNTAS INICIAIS; DATAFRAME, PYTHON, RESULTADO, ETC\n",
    "    pandas_prompt_str = (\"Você está trabalhando com um dataframe do pandas em Python chamado `DF`.\\n\"\n",
    "                            \"{colunas_detalhes}\\n\\n\"\n",
    "                            \"Este é o resultado de `print(DF.head())`:\\n\"\n",
    "                            \"{df_str}\\n\\n\"\n",
    "                            \"Siga estas instruções:\\n\"\n",
    "                            \"{instruction_str}\\n\"\n",
    "                            \"Consulta: {query_str}\\n\\n\"\n",
    "                            \"Expressão:\")\n",
    "\n",
    "    # GUIA PARA SINTETIZAR A RESPOSTA ATRAVÉS DA PERGUNTA FEITA\n",
    "    response_synthesis_prompt_str = (\"Dada uma pergunta de entrada, atue como analista de dados e elabore uma resposta a partir dos resultados da consulta.\\n\"\n",
    "                                        \"Responda de forma natural, sem introduções como 'A resposta é:' ou algo semelhante.\\n\"\n",
    "                                        \"Consulta: {query_str}\\n\\n\"\n",
    "                                        \"Instruções do Pandas (opcional):\\n{pandas_instructions}\\n\\n\"\n",
    "                                        \"Saída do Pandas: {pandas_output}\\n\\n\"\n",
    "                                        \"Resposta:\"\n",
    "                                        \"Ao final, exibir o código usado para gerar a resposta, no formato: O código utilizado foi {pandas_instructions}\")\n",
    "\n",
    "    pandas_prompt = PromptTemplate(pandas_prompt_str).partial_format(instruction_str=instruction_str, df_str=df.head(5), colunas_detalhes=descrição_colunas(df))\n",
    "\n",
    "    pandas_output_parser = PandasInstructionParser(df)\n",
    "    response_synthesis_prompt = PromptTemplate(response_synthesis_prompt_str)\n",
    "    \n",
    "    # Criação do Query Pipeline\n",
    "    qp = QP(modules={\"input\": InputComponent(),\n",
    "                        \"pandas_prompt\": pandas_prompt,\n",
    "                        \"llm1\": llm,\n",
    "                        \"pandas_output_parser\": pandas_output_parser,\n",
    "                        \"response_synthesis_prompt\": response_synthesis_prompt,\n",
    "                        \"llm2\": llm,},verbose=True,)\n",
    "    \n",
    "    qp.add_chain([\"input\", \"pandas_prompt\", \"llm1\", \"pandas_output_parser\"])\n",
    "    qp.add_links([Link(\"input\", \"response_synthesis_prompt\", dest_key=\"query_str\"),\n",
    "                  Link(\"llm1\", \"response_synthesis_prompt\", dest_key=\"pandas_instructions\"),\n",
    "                  Link(\"pandas_output_parser\", \"response_synthesis_prompt\", dest_key=\"pandas_output\")])\n",
    "    qp.add_link(\"response_synthesis_prompt\", \"llm2\")\n",
    "    \n",
    "    return qp\n",
    "\n",
    "def question_processing(question, DF_ESTADO):\n",
    "    if not DF_ESTADO.empty:\n",
    "        qp = pipeline_consulta(DF_ESTADO)\n",
    "        answer = qp.run(query_str=question)\n",
    "        return answer.message.content\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "with gr.Blocks() as app:\n",
    "    input_file = gr.File(file_count='single', type='filepath', label='Carregar Excel')\n",
    "    upload_status = gr.Textbox(label='Status do Upload')\n",
    "    input_question = gr.Textbox(label='Entre sua pergunta')\n",
    "    button_submit = gr.Button('Enviar')\n",
    "    output_answer = gr.Textbox(label='Resposta')\n",
    "    file_pdf = gr.File(label='Download do PDF')\n",
    "\n",
    "    DF_ESTADO = gr.State(value=None)\n",
    "\n",
    "    input_file.change(fn=load_data, inputs=[input_file, DF_ESTADO], outputs=[upload_status, DF_ESTADO])\n",
    "    button_submit.click(fn=question_processing, inputs=[input_question, DF_ESTADO], outputs=output_answer)\n",
    "\n",
    "app.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
